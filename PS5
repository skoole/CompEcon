%%PS5Q1
%To solve a minimization problem you take the max|-f|. An example of a
%finite dimensional maximization problem is finding max profit or max
%utility for a firm. We might find derivative-free methoda useful when
%the calculus is difficult and the function is not differentiable, ie,
%there are jagged points in the function.

%The max point is 0.8831

%Method 1
function demopt01
close all

disp(' ')
disp('DEMOPT01 Illustrates maximization via golden search')

x = nodeunif(500,0,3);

f = inline('1./x.*sin(x.^3)');

x1 = golden(f,0,1);
x2 = golden(f,2,3);
xx = golden(f,0,3);

close all
figure(1)
plot(x,f(x),'k',x1,f(x1),'k*',x2,f(x2),'k*')
title('Maximization of 1./x sin(x^3) via golden search') 

prtfigs(mfilename,'Maximization of 1./x sin(x^3) via golden search',1)

%Method 2
function y=f(x)
    y=(1/x)*sin(x^3)
    x=golden('f',0,3);%put these in separate notepad
    x=0:0.01:3;
    f=(1./x).*sin(x.^3);
    plot(x,f)    


%%
%Q2
%The Nelder-Mead algorithim is a derivative-free optimization method for
%multivariate functions that evaluates the objective function at n+1
%points. These points form a simplex which is illustrated in the code
%below. While the Nelder-Mead is simple, it is slow and unreliable. For
%problems that involve single optimization, the Nelder-Mead is useful. For
%those problems in which optimization is embedded in a larger problem that
%needs to be solved repeatedly, one might want to use another method. 

%Simplex Method Below
function demopt02
close all

disp(' ')
disp('DEMOPT02 Displays changes in a simplex')

S=[[0.5;0.5] [.65;1.75] [1.5;0.35]];
xy=[0.5 2.25 0.25 2.25];
xy=[0.5 2.225 0.35 2.15];


color0=[.7 .7 .7];
color1=[.2 .2 .2];
rvector=ones(3,1)*(2/2);
rfactor=1+2/2;

x1=S*rvector-rfactor*S(:,1);        % reflection
S1=S; S1(:,1)=x1;
x2=1.5*x1-0.5*S(:,1);                     % expansion
S2=S; S2(:,1)=x2;
x3=0.75*S(:,1)+0.25*x1;                     % contraction
S3=S; S3(:,1)=x3;
S4=S/2+S(:,2)*(ones(1,3)/2);        % shrinkage

fs=get(0,'DefaultTextFontSize')*(3/4);

close all
figure(1)
subplot(2,2,1)
patch(S(1,:),S(2,:),color0)
hold on
patch(S1(1,:),S1(2,:),color1)
hold off
axis(xy)
axis off
h=text(.35,.4,'A');
set(h,'FontSize',fs)
h=text(.55,1.9,'B');
set(h,'FontSize',fs)
h=text(1.5,.2,'C');
set(h,'FontSize',fs)
title('Reflection');

subplot(2,2,2)
patch(S(1,:),S(2,:),color0)
hold on
patch(S2(1,:),S2(2,:),color1)
hold off
axis(xy)
axis off
h=text(.35,.4,'A');
set(h,'FontSize',fs)
h=text(.55,1.9,'B');
set(h,'FontSize',fs)
h=text(1.5,.2,'C');
set(h,'FontSize',fs)
title('Expansion');

subplot(2,2,3)
patch(S(1,:),S(2,:),color0)
hold on
patch(S3(1,:),S3(2,:),color1)
hold off
axis(xy)
axis off
h=text(.35,.4,'A');
set(h,'FontSize',fs)
h=text(.55,1.9,'B');
set(h,'FontSize',fs)
h=text(1.5,.2,'C');
set(h,'FontSize',fs)
title('Contraction');

subplot(2,2,4)
patch(S(1,:),S(2,:),color0)
hold on
patch(S4(1,:),S4(2,:),color1)
hold off
axis(xy)
axis off
h=text(.35,.4,'A');
set(h,'FontSize',fs)
h=text(.55,1.9,'B');
set(h,'FontSize',fs)
h=text(1.5,.2,'C');
set(h,'FontSize',fs)
title('Shrinkage');

%Banana function below
function M=demopt03
close all

disp(' ')
disp('DEMOPT03 Demonstrates Nelder-Mead simplex method')

n = [20 20];
xmin = [-0.2 -0.2];
xmax = [ 1.2  1.2];
[x,xcoord] = nodeunif(n,xmin,xmax);
[x1,x2] = meshgrid(xcoord{1},xcoord{2}) ;

y = banana(x');
y = reshape(y,n(1),n(2))';
conts = -exp(0.25:0.5:20);

figure(1)
contour(xcoord{1},xcoord{2},y,conts,'k:')
xlabel('x_1'),ylabel('x_2')
title('Nelder-Mead Maximizes the Banana Function')

optset('neldmead','maxit',1);
k = 50;
x = [1;0];
warning off
[xx,S] = neldmead('banana',x);
warning on
hold on
hp = patch(S(1,:),S(2,:),[0.5 0.5 0.5]);
M  = moviein(k);
for i=1:k
  xvec(:,i) = x;
  warning off
  [x,S] = neldmead('banana',x,S);
  warning on
  set(hp,'xdata',S(1,:)','ydata',S(2,:)');
  M(:,i) = getframe;
end
hold off
optset('neldmead','defaults');

%for i=1:size(M,2),movie(M(:,i),0);end

figure(2)
plot(1,1,'o')
hold on
plot(xvec(1,:),xvec(2,:))
plot(xvec(1,:),xvec(2,:),'*')
contour(xcoord{1},xcoord{2},y,conts,'k:')
hold off
axis square
title('Nelder-Mead Maximization of Banana Function')
h=xlabel('x_1');
set(h,'VerticalAlignment','cap')
h=ylabel('x_2');
set(h,'VerticalAlignment','bottom')
axis([-.2 1.2 -.2 1.2])
set(gca,'ytick',[0 0.5 1])

prtfigs(mfilename,'Nelder-Mead Maximization of Banana Function',2)
prtfigs(mfilename, 'Simplex Transformations in the Nelder-Mead Algorithm',1)

%%Q3
%Two drawbacks of the Newton-Raphson Method include: requiring the
%computation of both the first and second derivatives of the objective
%function, and the lack of guarantee that the objective function value will
%increase in the direction of the Newton step. When dTu becomes too small,
%we recognize |dTu| < e ||d|| ||u||, where e is the precision of the
%computer. If this is the case, then we skip updating B^(k)and 
%reset the inverse Hessian approximant to a scaled negative identity
%matrix. Using qnewton we can adjust the first five options using the
%following piece of code:
%optset(’qnewton’,’searchmeth’,5); x = qnewton(f,[1;0]). 

%According to the code below, BFGS converges the fastest in 43 iterations. 
disp(' ')
disp('DEMOPT04 Demonstrates Quasi-Newton maximization')
warning off

n = [20 20];
xmin = [-1.5 -1.5];
xmax = [ 4  4];
[x,xcoord] = nodeunif(n,xmin,xmax);
[x1,x2] = meshgrid(xcoord{1},xcoord{2}) ;

y =banana(x');
y = reshape(y,n(1),n(2))';
conts = -44:(2+44)/19:2;

optset('qnewton','maxit',1);
optset('qnewton','ShowIters',1);

'Steepest Ascent Maximization'
optset('qnewton','SearchMeth',1);
k = 100;
x0 = [-1;2];
x=x0;
A=[];
for i=1:k
  xx1(:,i) = x;
  [x,A] = qnewton('banana',x,A);
  if norm(x-[1;1])>sqrt(eps), iters1=i; end
end

'DFP Maximization'
optset('qnewton','SearchMeth',2);
x=x0;
A=[];
for i=1:k
  xx2(:,i) = x;
  [x,A] = qnewton('banana',x,A);
  if norm(x-[1;1])>sqrt(eps), iters2=i; end
end

'BFGS Maximization'
optset('qnewton','SearchMeth',3);
x=x0;
A=[];
for i=1:k
  xx3(:,i) = x;
  [x,A] = qnewton('banana',x,A);
  if norm(x-[1;1])>sqrt(eps), iters3=i; end
end

figure(1)
plot(1,1,'o')
hold on
plot(xx1(1,:),xx1(2,:))
plot(xx1(1,:),xx1(2,:),'*')
contour(xcoord{1},xcoord{2},y,conts,'k:')
hold off
axis square
title('Steepest Ascent Maximization of Banana Function')
h=xlabel('x_1');
set(h,'VerticalAlignment','cap')
h=ylabel('x_2');
set(h,'VerticalAlignment','bottom')
xlim([xmin(1) xmax(1)])
ylim([xmin(2) xmax(2)])
set(gca,'ytick',[0 0.5 1])

figure(2)
plot(1,1,'o')
hold on
plot(xx2(1,:),xx2(2,:))
plot(xx2(1,:),xx2(2,:),'*')
contour(xcoord{1},xcoord{2},y,conts,'k:')
hold off
axis square
title('DFP Quasi-Newton Maximization of Banana Function')
h=xlabel('x_1');
set(h,'VerticalAlignment','cap')
h=ylabel('x_2');
set(h,'VerticalAlignment','bottom')
xlim([xmin(1) xmax(1)])
ylim([xmin(2) xmax(2)])
set(gca,'ytick',[0 0.5 1])

figure(3)
plot(1,1,'o')
hold on
plot(xx3(1,:),xx3(2,:))
plot(xx3(1,:),xx3(2,:),'*')
contour(xcoord{1},xcoord{2},y,conts,'k:')
hold off
axis square
title('BFGS Quasi-Newton Maximization of Banana Function')
h=xlabel('x_1');
set(h,'VerticalAlignment','cap')
h=ylabel('x_2');
set(h,'VerticalAlignment','bottom')
xlim([xmin(1) xmax(1)])
ylim([xmin(2) xmax(2)])
set(gca,'ytick',[0 0.5 1])
s={'Iterations';
   ['Steepest: ' num2str(iters1+1)];...
   ['DFP:      ' num2str(iters2+1)];...
   ['BFGS:     ' num2str(iters3+1)]};
disp(s)

optset('qnewton','maxit',250)

%%
% Q4
%The main difference between the Armijo and Goldstein search is that the Armijo search is 
% both selects candidate values of the step size s and is a stopping rule,
% while the Goldstein search is simply a stopping rule that is used with a
% variety of search approaches. The bhhhstep approach locates a point by
% first finding a point in or below the cone using step doubling. In this
% case, we can backstep until a point inside the cone is obtained if a
% point below the cone is found first. The stepbt approach is faster and
% gives better results. It works by maximizing a quadratic approximation to
% the objective function in the Newton direction of f(x), f'(x)d, and
% f(x+d) if s=1. If this is not the case, then it iterates until a step is
% found using cubic approximation from f(x), f'(x)d, f(x+s^(j-1)d), and
% f(x+s^(j)d). Stepgold is the golden search step length maximizer. With
% all these methods, it is recommended to default to step stepbt. 

%Below is the code for the graph
function demopt05
close all

disp(' ')
disp('DEMOPT05 Step length determination')

x=[0.975;.95];

[fx,g0]=banana(x);
d=g0;
optset('optstep','bhhhcone',0.25);
[s1,fx1,errcode,iters1]=optstep(2,'banana',x,fx,g0,d,25);
[s2,fx2,errcode,iters2]=optstep(3,'banana',x,fx,g0,d,25);
[s3,fx3,errcode,iters3]=optstep(4,'banana',x,fx,g0,d,25);
optset('optstep','defaults');
dg=d'*g0;
delta=0.25;
%s=(-0.0010:0.0001:.0025);
s=(-0.0005:0.0001:.0020);
n=length(s);
fs=banana(x(:,ones(n,1))+g0*s);

close all
figure(1)
plot(s,fs-fx,'linewidth',1.5);
hold on
plot(s1,banana(x+s1*d)-fx,'*')
plot(s2,banana(x+s2*d)-fx,'*')
plot(s3,banana(x+s3*d)-fx,'*')
plot(s,s*dg)
ylims=get(gca,'ylim');
plot(s,0,':')
plot([0;0],ylims,':')
s=s(find(s>=0));
plot(s,s*dg*delta,'--')
plot(s,s*dg*(1-delta),'--')
h=text(1.5e-3,ylims(2)/2+4e-5, ...
  {['BHHHSTEP:  s = ' sprintf('%10.8f',s1)];...
   ['  STEPBT:  s = ' sprintf('%10.8f',s2)];...
   ['GOLDSTEP:  s = ' sprintf('%10.8f',s3)]});
fs=get(0,'DefaultTextFontSize')*(3/4);
set(h,'HorizontalAlignment','right','FontSize',fs)
hold off
title('Step Length Determination')
xlabel('s')
ylabel('f(x+sd-f(x))') %changing ylabel

s={'Iterations';
   ['  BTSTEP: ' num2str(iters2)];...
   ['STEPBHHH: ' num2str(iters1)];...
   ['STEPGOLD: ' num2str(iters3)]};
disp(s)

prtfigs(mfilename,'Step Length Determination',1)
